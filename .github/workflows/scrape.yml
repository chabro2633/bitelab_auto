name: Cigro Data Scraping

on:
  # ë§¤ì¼ ì˜¤ì „ 8ì‹œ (í•œêµ­ì‹œê°„)ì— ìžë™ ì‹¤í–‰
  schedule:
    - cron: '0 23 * * *'  # UTC ê¸°ì¤€ 23ì‹œ (í•œêµ­ì‹œê°„ ì˜¤ì „ 8ì‹œ)
  
  # ìˆ˜ë™ ì‹¤í–‰ ê°€ëŠ¥
  workflow_dispatch:
    inputs:
      date:
        description: 'ìŠ¤í¬ëž˜í•‘í•  ë‚ ì§œ (YYYY-MM-DD í˜•ì‹, ë¹„ì›Œë‘ë©´ ì–´ì œ ë‚ ì§œ)'
        required: false
        type: string
      brands:
        description: 'ìŠ¤í¬ëž˜í•‘í•  ë¸Œëžœë“œ ëª©ë¡ (ê³µë°±ìœ¼ë¡œ êµ¬ë¶„, ë¹„ì›Œë‘ë©´ ëª¨ë“  ë¸Œëžœë“œ)'
        required: false
        type: string

jobs:
  scrape-data:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y wget gnupg
        
    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Install Playwright browsers
      run: |
        playwright install chromium
        playwright install-deps chromium
        
    - name: Create Google Sheets credentials
      run: |
        # JSON íŒŒì¼ì„ ë” ì•ˆì „í•˜ê²Œ ìƒì„±
        cat > google_sheet_credentials.json << 'EOF'
        ${{ secrets.GOOGLE_SHEETS_CREDENTIALS }}
        EOF
        
        # JSON í˜•ì‹ ê²€ì¦
        python -c "import json; json.load(open('google_sheet_credentials.json')); print('âœ… JSON í˜•ì‹ì´ ì˜¬ë°”ë¦…ë‹ˆë‹¤.')"
        
    - name: Run scraping script
      env:
        EMAIL: ${{ secrets.CIGRO_EMAIL }}
        PASSWORD: ${{ secrets.CIGRO_PASSWORD }}
        GOOGLE_SHEET_NAME: ${{ secrets.GOOGLE_SHEET_NAME }}
        SCRAPE_DATE: ${{ github.event.inputs.date }}
        SCRAPE_BRANDS: ${{ github.event.inputs.brands }}
      run: |
        python_command="python cigro_yesterday.py"
        
        if [ -n "$SCRAPE_DATE" ]; then
          echo "íŠ¹ì • ë‚ ì§œë¡œ ìŠ¤í¬ëž˜í•‘: $SCRAPE_DATE"
          python_command="$python_command --date \"$SCRAPE_DATE\""
        else
          echo "ì–´ì œ ë‚ ì§œë¡œ ìŠ¤í¬ëž˜í•‘"
        fi
        
        if [ -n "$SCRAPE_BRANDS" ]; then
          echo "ì„ íƒëœ ë¸Œëžœë“œ: $SCRAPE_BRANDS"
          python_command="$python_command --brands $SCRAPE_BRANDS"
        else
          echo "ëª¨ë“  ë¸Œëžœë“œ ìŠ¤í¬ëž˜í•‘"
        fi
        
        echo "ì‹¤í–‰ ëª…ë ¹ì–´: $python_command"
        eval $python_command
        
    - name: Upload logs
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: scraping-logs
        path: |
          *.log
          auth.json
        retention-days: 7
        
    - name: Send notification on success
      if: success()
      run: |
        echo "âœ… Cigro ë°ì´í„° ìŠ¤í¬ëž˜í•‘ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!"
        echo "ðŸ“… ì‹¤í–‰ ì‹œê°„: $(date)"
        echo "ðŸ“Š ë°ì´í„°ê°€ Google Sheetsì— ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤."
        
    - name: Send notification on failure
      if: failure()
      run: |
        echo "âŒ Cigro ë°ì´í„° ìŠ¤í¬ëž˜í•‘ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤!"
        echo "ðŸ“… ì‹¤í–‰ ì‹œê°„: $(date)"
        echo "ðŸ” ë¡œê·¸ë¥¼ í™•ì¸í•˜ì—¬ ë¬¸ì œë¥¼ íŒŒì•…í•˜ì„¸ìš”."
