name: Cigro Data Scraping

on:
  # ë§¤ì¼ ì˜¤ì „ 8ì‹œ (í•œêµ­ì‹œê°„)ì— ìžë™ ì‹¤í–‰
  schedule:
    - cron: '0 23 * * *'  # UTC ê¸°ì¤€ 23ì‹œ (í•œêµ­ì‹œê°„ ì˜¤ì „ 8ì‹œ)
  
  # ìˆ˜ë™ ì‹¤í–‰ ê°€ëŠ¥
  workflow_dispatch:
    inputs:
      date:
        description: 'ìŠ¤í¬ëž˜í•‘í•  ë‚ ì§œ (YYYY-MM-DD í˜•ì‹, ë¹„ì›Œë‘ë©´ ì–´ì œ ë‚ ì§œ)'
        required: false
        type: string
      brands:
        description: 'ìŠ¤í¬ëž˜í•‘í•  ë¸Œëžœë“œ ëª©ë¡ (ê³µë°±ìœ¼ë¡œ êµ¬ë¶„, ë¹„ì›Œë‘ë©´ ëª¨ë“  ë¸Œëžœë“œ)'
        required: false
        type: string

jobs:
  scrape-data:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install system dependencies
      run: |
        # ìºì‹œëœ íŒ¨í‚¤ì§€ ëª©ë¡ ì‚¬ìš©ìœ¼ë¡œ ì—…ë°ì´íŠ¸ ì‹œê°„ ë‹¨ì¶•
        sudo apt-get update -o Acquire::Check-Valid-Until=false -o Acquire::Check-Date=false
        # í•„ìš”í•œ íŒ¨í‚¤ì§€ë§Œ ì„¤ì¹˜ (wget, gnupgëŠ” ì´ë¯¸ ê¸°ë³¸ ì„¤ì¹˜ë¨)
        sudo apt-get install -y --no-install-recommends ca-certificates
        
    - name: Cache Python dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
          
    - name: Cache Playwright browsers
      uses: actions/cache@v3
      with:
        path: ~/.cache/ms-playwright
        key: ${{ runner.os }}-playwright-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-playwright-
          
    - name: Install dependencies and browsers (parallel)
      run: |
        # Python ì˜ì¡´ì„±ê³¼ Playwright ë¸Œë¼ìš°ì €ë¥¼ ë³‘ë ¬ë¡œ ì„¤ì¹˜
        python -m pip install --upgrade pip &
        pip install --cache-dir ~/.cache/pip -r requirements.txt &
        playwright install chromium --with-deps &
        wait
        
    - name: Create Google Sheets credentials
      run: |
        # JSON íŒŒì¼ì„ ë” ì•ˆì „í•˜ê²Œ ìƒì„±
        cat > google_sheet_credentials.json << 'EOF'
        ${{ secrets.GOOGLE_SHEETS_CREDENTIALS }}
        EOF
        
        # JSON í˜•ì‹ ê²€ì¦
        python -c "import json; json.load(open('google_sheet_credentials.json')); print('âœ… JSON í˜•ì‹ì´ ì˜¬ë°”ë¦…ë‹ˆë‹¤.')"
        
    - name: Run scraping script
      env:
        EMAIL: ${{ secrets.CIGRO_EMAIL }}
        PASSWORD: ${{ secrets.CIGRO_PASSWORD }}
        GOOGLE_SHEET_NAME: ${{ secrets.GOOGLE_SHEET_NAME }}
        SCRAPE_DATE: ${{ github.event.inputs.date }}
        SCRAPE_BRANDS: ${{ github.event.inputs.brands }}
      run: |
        python_command="python cigro_yesterday.py"
        
        if [ -n "$SCRAPE_DATE" ]; then
          echo "íŠ¹ì • ë‚ ì§œë¡œ ìŠ¤í¬ëž˜í•‘: $SCRAPE_DATE"
          python_command="$python_command --date \"$SCRAPE_DATE\""
        else
          echo "ì–´ì œ ë‚ ì§œë¡œ ìŠ¤í¬ëž˜í•‘"
        fi
        
        if [ -n "$SCRAPE_BRANDS" ]; then
          echo "ì„ íƒëœ ë¸Œëžœë“œ: $SCRAPE_BRANDS"
          python_command="$python_command --brands $SCRAPE_BRANDS"
        else
          echo "ëª¨ë“  ë¸Œëžœë“œ ìŠ¤í¬ëž˜í•‘"
        fi
        
        echo "ì‹¤í–‰ ëª…ë ¹ì–´: $python_command"
        eval $python_command
        
    - name: Upload logs
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: scraping-logs
        path: |
          *.log
          auth.json
        retention-days: 7
        
    - name: Send notification on success
      if: success()
      run: |
        echo "âœ… Cigro ë°ì´í„° ìŠ¤í¬ëž˜í•‘ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!"
        echo "ðŸ“… ì‹¤í–‰ ì‹œê°„: $(date)"
        echo "ðŸ“Š ë°ì´í„°ê°€ Google Sheetsì— ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤."
        
    - name: Send notification on failure
      if: failure()
      run: |
        echo "âŒ Cigro ë°ì´í„° ìŠ¤í¬ëž˜í•‘ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤!"
        echo "ðŸ“… ì‹¤í–‰ ì‹œê°„: $(date)"
        echo "ðŸ” ë¡œê·¸ë¥¼ í™•ì¸í•˜ì—¬ ë¬¸ì œë¥¼ íŒŒì•…í•˜ì„¸ìš”."
