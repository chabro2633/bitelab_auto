#!/usr/bin/env python3
"""
Meta Ads Library ìŠ¤í¬ë˜í•‘ ìŠ¤í¬ë¦½íŠ¸
- GitHub Actionsì—ì„œ ì‹¤í–‰
- ê²°ê³¼ë¥¼ Vercel KVì— ì €ì¥
"""

import os
import sys
import json
import urllib.request
import urllib.parse
import urllib.error
import argparse
import logging
from datetime import datetime, timezone, timedelta
from playwright.sync_api import sync_playwright

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler(sys.stdout)]
)
logger = logging.getLogger(__name__)

# í™˜ê²½ ë³€ìˆ˜
VERCEL_KV_URL = os.getenv("KV_REST_API_URL")
VERCEL_KV_TOKEN = os.getenv("KV_REST_API_TOKEN")

def save_to_vercel_kv(key: str, data: dict, ttl: int = 3600):
    """Vercel KVì— ë°ì´í„° ì €ì¥ (TTL: 1ì‹œê°„)"""
    if not VERCEL_KV_URL or not VERCEL_KV_TOKEN:
        logger.warning("âš ï¸ Vercel KV í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return False

    try:
        url = f"{VERCEL_KV_URL}/set/{key}"
        payload = json.dumps(data).encode('utf-8')

        req = urllib.request.Request(
            url,
            data=payload,
            headers={
                'Authorization': f'Bearer {VERCEL_KV_TOKEN}',
                'Content-Type': 'application/json'
            },
            method='POST'
        )

        # TTL ì„¤ì •
        req.add_header('ex', str(ttl))

        with urllib.request.urlopen(req, timeout=30) as response:
            if response.status == 200:
                logger.info(f"âœ… Vercel KV ì €ì¥ ì™„ë£Œ: {key}")
                return True
            else:
                logger.error(f"âŒ Vercel KV ì €ì¥ ì‹¤íŒ¨: HTTP {response.status}")
                return False
    except Exception as e:
        logger.error(f"âŒ Vercel KV ì €ì¥ ì˜¤ë¥˜: {e}")
        return False


def scrape_meta_ads(search_query: str, max_scroll: int = 15, scroll_pause: float = 2.0):
    """Meta Ads Libraryì—ì„œ ê´‘ê³  ë¯¸ë””ì–´ ìˆ˜ì§‘"""
    logger.info(f"ğŸ” ê²€ìƒ‰ì–´: {search_query}")

    media_items = []

    with sync_playwright() as p:
        browser = p.chromium.launch(
            headless=True,
            args=['--no-sandbox', '--disable-dev-shm-usage', '--disable-gpu']
        )

        context = browser.new_context(
            user_agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            viewport={'width': 1920, 'height': 1080}
        )

        page = context.new_page()

        # Meta Ads Library URL
        encoded_query = urllib.parse.quote(search_query)
        url = f"https://www.facebook.com/ads/library/?active_status=active&ad_type=all&country=KR&is_targeted_country=false&media_type=all&q={encoded_query}&search_type=keyword_unordered"

        logger.info(f"ğŸ“„ í˜ì´ì§€ ë¡œë”©: {url}")
        page.goto(url, wait_until='networkidle', timeout=60000)
        page.wait_for_timeout(3000)

        # ìŠ¤í¬ë¡¤ ë‹¤ìš´
        logger.info(f"ğŸ“œ ìŠ¤í¬ë¡¤ ì‹œì‘ (ìµœëŒ€ {max_scroll}íšŒ)...")
        scroll_count = 0
        prev_height = 0

        for i in range(max_scroll):
            prev_height = page.evaluate("document.body.scrollHeight")
            page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
            page.wait_for_timeout(int(scroll_pause * 1000))

            new_height = page.evaluate("document.body.scrollHeight")
            scroll_count = i + 1

            if new_height == prev_height:
                logger.info(f"ğŸ“œ ìŠ¤í¬ë¡¤ ì™„ë£Œ (ë” ì´ìƒ ì½˜í…ì¸  ì—†ìŒ): {scroll_count}íšŒ")
                break

        logger.info(f"ğŸ“œ ìŠ¤í¬ë¡¤ ì™„ë£Œ: {scroll_count}íšŒ")

        # ë¯¸ë””ì–´ ìˆ˜ì§‘
        logger.info("ğŸ–¼ï¸ ë¯¸ë””ì–´ ìˆ˜ì§‘ ì¤‘...")

        seen_urls = set()

        # ì´ë¯¸ì§€ ìˆ˜ì§‘
        images = page.query_selector_all('img')
        for img in images:
            try:
                src = img.get_attribute('src')
                if not src:
                    continue

                # í•„í„°ë§
                skip_keywords = ['safe_image.php', 'profilepic', 'logo', 'fbcdn-profile', 'emoji', 'rsrc.php', 'static']
                if any(kw in src for kw in skip_keywords):
                    continue

                # ì‘ì€ ì´ë¯¸ì§€ ì œì™¸
                width = img.get_attribute('width')
                if width and int(width) < 100:
                    continue

                if src not in seen_urls:
                    seen_urls.add(src)
                    box = img.bounding_box()
                    media_items.append({
                        'url': src,
                        'type': 'image',
                        'width': int(box['width']) if box else None,
                        'height': int(box['height']) if box else None
                    })
            except Exception as e:
                logger.debug(f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")

        # ë¹„ë””ì˜¤ ìˆ˜ì§‘
        videos = page.query_selector_all('video')
        for video in videos:
            try:
                src = video.get_attribute('src')
                if src and src not in seen_urls:
                    seen_urls.add(src)
                    media_items.append({
                        'url': src,
                        'type': 'video'
                    })

                # source íƒœê·¸ í™•ì¸
                sources = video.query_selector_all('source')
                for source in sources:
                    src = source.get_attribute('src')
                    if src and src not in seen_urls:
                        seen_urls.add(src)
                        media_items.append({
                            'url': src,
                            'type': 'video'
                        })
            except Exception as e:
                logger.debug(f"ë¹„ë””ì˜¤ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")

        browser.close()

    logger.info(f"âœ… ë¯¸ë””ì–´ ìˆ˜ì§‘ ì™„ë£Œ: {len(media_items)}ê°œ")
    return media_items, scroll_count


def main():
    parser = argparse.ArgumentParser(description='Meta Ads Library ìŠ¤í¬ë˜í•‘')
    parser.add_argument('--query', '-q', type=str, required=True, help='ê²€ìƒ‰ì–´')
    parser.add_argument('--request-id', '-r', type=str, required=True, help='ìš”ì²­ ID (ê²°ê³¼ ì €ì¥ìš©)')
    parser.add_argument('--max-scroll', type=int, default=15, help='ìµœëŒ€ ìŠ¤í¬ë¡¤ íšŸìˆ˜')
    args = parser.parse_args()

    logger.info("ğŸš€ Meta Ads ìŠ¤í¬ë˜í•‘ ì‹œì‘")
    logger.info(f"ğŸ“‹ ìš”ì²­ ID: {args.request_id}")

    KST = timezone(timedelta(hours=9))
    start_time = datetime.now(KST)

    try:
        media_items, scroll_count = scrape_meta_ads(
            search_query=args.query,
            max_scroll=args.max_scroll
        )

        end_time = datetime.now(KST)

        result = {
            'success': True,
            'requestId': args.request_id,
            'searchQuery': args.query,
            'totalItems': len(media_items),
            'scrollCount': scroll_count,
            'items': media_items,
            'startTime': start_time.isoformat(),
            'endTime': end_time.isoformat(),
            'duration': (end_time - start_time).total_seconds()
        }

        # Vercel KVì— ì €ì¥
        kv_key = f"meta-ads:{args.request_id}"
        save_to_vercel_kv(kv_key, result, ttl=3600)  # 1ì‹œê°„ TTL

        # ê²°ê³¼ ì¶œë ¥ (GitHub Actions ë¡œê·¸ìš©)
        logger.info("=" * 50)
        logger.info(f"âœ… ìŠ¤í¬ë˜í•‘ ì™„ë£Œ!")
        logger.info(f"ğŸ“Š ê²€ìƒ‰ì–´: {args.query}")
        logger.info(f"ğŸ–¼ï¸ ìˆ˜ì§‘ëœ ë¯¸ë””ì–´: {len(media_items)}ê°œ")
        logger.info(f"â±ï¸ ì†Œìš” ì‹œê°„: {result['duration']:.1f}ì´ˆ")
        logger.info("=" * 50)

        # JSON ê²°ê³¼ ì¶œë ¥ (ë””ë²„ê¹…ìš©)
        print(json.dumps(result, ensure_ascii=False, indent=2))

    except Exception as e:
        logger.error(f"âŒ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {e}")

        error_result = {
            'success': False,
            'requestId': args.request_id,
            'searchQuery': args.query,
            'error': str(e),
            'endTime': datetime.now(KST).isoformat()
        }

        # ì—ëŸ¬ë„ KVì— ì €ì¥
        kv_key = f"meta-ads:{args.request_id}"
        save_to_vercel_kv(kv_key, error_result, ttl=3600)

        sys.exit(1)


if __name__ == "__main__":
    main()
